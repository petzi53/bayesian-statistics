{
  "hash": "2840326a767c3ae5ae2e0965c6387ab9",
  "result": {
    "markdown": "# Probability {#sec-probability}\n\n## File setup {.unnumbered}\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(glossary)\nglossary_path(\"glossary.yml\")\nglossary_popup(\"hover\")\n```\n:::\n\n\n```{.r .cell-code}\nglossary_style(color = \"#0066cc\", \n               text_decoration = \"underline double 1px\",\n               def_bg = \"#333\",\n               def_color = \"white\")\n```\n\n<style>\na.glossary {\n  color: #0066cc;\n  text-decoration: underline double 1px;\n  cursor: help;\n  position: relative;\n}\n\n/* only needed for popup = \"click\" */\n/* popup-definition */\na.glossary .def {\n  display: none;\n  position: absolute;\n  z-index: 1;\n  width: 200px;\n  bottom: 100%;\n  left: 50%;\n  margin-left: -100px;\n  background-color: #333;\n  color: white;\n  padding: 5px;\n  border-radius: 6px;\n}\n/* show on click */\na.glossary:active .def {\n  display: inline-block;\n}\n/* triangle arrow */\na.glossary:active .def::after {\n  content: ' ';\n  position: absolute;\n  top: 100%;\n  left: 50%;\n  margin-left: -5px;\n  border-width: 5px;\n  border-style: solid;\n  border-color: #333 transparent transparent transparent;\n}\n</style>\n\n\n## Mission Statement\n\nIn Bayesian statistics, we formulate models in terms of entities called\nprobability distributions. This chapter provides an introduction to all\nthings related to probability.\n\n## Chapter Goals\n\nThe chapter focuses on probability distribution: - We define what is\nmeant by probability distribution. - We discuss why the distinction\nbetween likelihoods and probabilities is important. - We explain how to\nmanipulate probability distributions in order to derive quantities of\ninterest. - We show how to derive the Bayesian formula from the law of\nconditional probability.\n\n## Probability Distributions: Helping us to Explicitly State our Ignorance\n\n::: {#lem-random-variables}\n##### Random variables and probability distributions\n\n\n{{< video https://youtu.be/pvkhK03aFDM?si=sbI9_WI0ICjgEQuq >}}\n\n\n:::\n\nThe mathematical theory of probability provides a logic and language\nwhich is the only completely consistent framework to describe situations\ninvolving uncertainty. In probability theory, we describe the behaviour\nof random variables. This is a statistical term for variables that\nassociate different numeric values with each of the possible outcomes of\nsome random process. By random here we do not mean the colloquial use of\nthis term to mean something that is entirely unpredictable. A random\nprocess is simply a process whose outcome cannot be perfectly known\nahead of time (it may nonetheless be quite predictable).\n\n### What makes a probability distribution valid?\n\n::: {#lem-prob-dist}\n##### What is a probability distribution?\n\n\n{{< video https://youtu.be/4Ghtj_iTSpI?si=5J13qlUPoE9QZIgZ >}}\n\n\n:::\n\n1.  All values of the distribution must be real and non-negative.\n2.  The sum (for discrete random variables) or integral (for continuous\n    random variables) across all possible values of the random variable\n    must be 1.\n\nThis definition is of central importance to Bayesian statistics. Only\nvalid probability distributions can be used to describe uncertainty. The\npursuit of this ideal underlies the majority of all methods in applied\nBayesian statistics -- analytic and computational -- and hence its\nimportance cannot be overstated!\n\n::: {#lem-discrete-prob-dist}\n##### An introduction to discrete probability distributions\n\n\n{{< video https://youtu.be/4Ghtj_iTSpI?si=DYV0uTsKrz3w9jVZ >}}\n\n\n:::\n\n::: {#lem-continous-prob-dist}\n##### An introduction to continuous probability distributions\n\n\n{{< video https://youtu.be/s87mffcX0xU?si=_As5GZMSPCZEft76 >}}\n\n\n:::\n\n### Probabilities versus probability densities: interpreting discrete and continuous probability distributions\n\nWe can't assign probabilities to every possible value of continuous\ndistributions as we can do with discrete distributions. The reason is\nthat there would be infinite values (e.g., \\$2500, \\$2500.10, \\$2500.01,\n\\$2500.001). If we would sum up all these values we would not get 1 but\ninfinity.\n\nIf we reconsider the test values {\\$2500, \\$2500.10, \\$2500.01,\n\\$2500.001}, we reason that these are all equally unlikely and belong to\na set of an infinite number of potential values that we could draw. This\nmeans that, for a continuous random variable, we always have\n`Pr(Œ∏ = number) = 0`, to avoid an infinite sum. Hence, when we consider\n`p(Œ∏)` for a continuous random variable, it turns out we should\ninterpret its values as\n<a class='glossary' title='Probability density is a ‚Äúdensity‚Äù function f(X). The density determines what the probabilities will be over a given range. The probability density function for a given value of random variable X represents the density of probability (probability per unit random variable) within a particular range of that random variable X. Probability densities can take values larger than 1. (StackExchange Mathematics) We can use a continuous probability distribution to calculate the probability that a random variable lies within an interval of possible values. To do this, we use the continuous analogue of a sum, an integral. However, we recognise that calculating an integral is equivalent to calculating the area under a probability density curve. We use p(value) for probability densities and Pr for probabilities. (Chap.3)'>probability densities</a>, not\n<a class='glossary' title='Probability is a mathematical tool used to study randomness. It deals with the chance of an event occurring. (OpenStax: Statistics) In the discrete case, to calculate the probability that a random variable takes on any value within a range, we sum the individual probabilities corresponding to each of the values. We use Pr to explicitly state that the result is a probability from a discrete probability distribution, whereas p(value) is a probability density from a continuous probability distribution. (Chap.3)'>probabilities</a>.\n\nThere are events that are impossible. These events have zero\nprobability. However, the converse is not true: some events that are of\nzero probability are still possible.\n\nWhile it is important to understand that <a class='glossary' title='Probability is a mathematical tool used to study randomness. It deals with the chance of an event occurring. (OpenStax: Statistics) In the discrete case, to calculate the probability that a random variable takes on any value within a range, we sum the individual probabilities corresponding to each of the values. We use Pr to explicitly state that the result is a probability from a discrete probability distribution, whereas p(value) is a probability density from a continuous probability distribution. (Chap.3)'>probabilities</a>\nand <a class='glossary' title='Probability density is a ‚Äúdensity‚Äù function f(X). The density determines what the probabilities will be over a given range. The probability density function for a given value of random variable X represents the density of probability (probability per unit random variable) within a particular range of that random variable X. Probability densities can take values larger than 1. (StackExchange Mathematics) We can use a continuous probability distribution to calculate the probability that a random variable lies within an interval of possible values. To do this, we use the continuous analogue of a sum, an integral. However, we recognise that calculating an integral is equivalent to calculating the area under a probability density curve. We use p(value) for probability densities and Pr for probabilities. (Chap.3)'>probability densities</a> are not\nthe same types of entity, the good news for us is that\n<a class='glossary' title='This is the theorem that gives Bayesian data analysis its name. But the theorem itself is a trivial implication of probability theory. The mathematical definition of the posterior distribution arises from Bayes‚Äô Theorem. The key lesson is that the posterior is proportional to the product of the prior and the probability of the data. (SR2, Chap.2)'>Bayes‚Äô rule</a> is the same for each.\n\n\n::: {#thm-bayes-rule-dist-cont}\n\n##### Bayes‚Äô rule for discrete and continuous distributions\n$$\n\\begin{align*}\nPr(ùõ©=1\\|X=1) = \\frac{Pr(X=1|ùõ©=0)Pr(ùõ©=1)}{Pr(X=1)} \\\\\np(ùõ©=1\\|X=1) = \\frac{p(X=1|ùõ©=0)p(ùõ©=1)}{p(X=1)}\n\\end{align*}\n$$ {#eq-bayes-rule-dist-cont}\n\n:::\n\n### The mean of distributions\n\nA popular way of summarising a distribution is by its *mean*, which is a measure of central tendency for a distribution. More intuitively, a mean, or *expected value*, of a distribution is the long-run average value that would be obtained if we sampled from it an infinite number of times.\n\n### Generalising probability distributions to two dimensions (2D)\n\nLife is often more complex than the (1D) examples encountered thus far. We often must reason about the outcomes of a number of processes, whose results may be interdependent. We begin by considering the outcome of two measurements to introduce the mechanics of two-dimensional probability distributions. Fortunately, these rules do not become more complex when generalising to higher dimensional problems.\n\n#### Matt‚Äôs horses: a 2D discrete probability example\n\nImagine that you are a horse racing aficionado and want to quantify the uncertainty in the outcome of two separate races. In each race there are two horses from a particular stable, called A and B. From their historical performance over 100 races, you notice that both horses often react the same way to the racing conditions. When horse A wins, it is more likely that, later in the day, B will also win, and vice versa, with similar interrelations for the losses; when A finds conditions tough, so does B.\n\n|            | A-lose (0) | A-Win (1)¬† |\n| :--------- | :--------: | :--------: |\n| B-LOSE (0) |    0.3     |        0.1 |\n| B-WIN (1)  |    0.1     |        0.5 |\n: A probability distribution indicating the historical performance of two horses, A and B, that race in separate events {#tbl-horse-race}\n\nThis distribution satisfy the requirements for a valid probability distribution because:\n1. All the values of the distribution are real and non-negative\n2. The sum of all cells of the two discrete random variables results in 1, e.g. the distribution is normalized.\n\nThe table displays the outcome of two random variables. Since the probability distribution is a function of two variables, we say that it is two-dimensional (2D).\n\nInterpret the table we can say that it is very unlikely that one horse win and the other lose (10% each). The highest probability is that both horses win (50%). An intermediate probability of 30% is assigned to the case that both horses lose.\n\n\n::: {#lem-2d-discrete-dist}\n##### 2D discrete distributions: an introduction\n\n{{< video https://youtu.be/trWTk31jYQU?si=JmwlKuJAidVYEL8m >}}\n\n\n:::\n\n#### Foot length and literacy: a 2D continuous probability example\n\nSuppose that we measure the foot size and literacy test scores for a group of individuals. Both of these variables can be assumed to be continuous, meaning that we represent our strength of beliefs by specifying a two-dimensional probability distribution across a continuum of values. Since this distribution is two-dimensional we need three dimensions to plot it ‚Äì two dimensions for the variables and one dimension for the probability density. These three-dimensional plots are, however, a bit cumbersome to deal with, and so we prefer to use contour plots to graph two-dimensional continuous probability distributions. In <a class='glossary' title='Contour plots are a way to show a three-dimensional surface on a two-dimensional plane. A contour plot is appropriate if you want to see how some value Z changes as a function of two inputs, X and Y: z = f(x, y). Contour lines indicate levels that are the same. (Statistics How To)'>contour plots</a>, we mark the set of positions where the value of the probability density function is constant, as contour lines. The rate of change of the gradient of the function at a particular position in parameter space is, hence, determined by the local density of contour lines.\n\n::: {#lem-2d-cont-dist}\n##### 2D continuous distributions: an introduction\n\n\n{{< video https://youtu.be/0BxDoyiZd44?si=Q1KlEFDmvp2xUJZy >}}\n\n\n:::\n\n### Marginal distributions\n\nAlthough in the horse racing example there are two separate races, each with an uncertain outcome, we can still consider the outcome of one race on its own. Suppose, for example, that we witness only the result for A. What would be the probability distribution that describes this outcome?\n\nTo calculate this, we must average out the dependence of the other variable. Since we are interested only in the result of A, we can sum down the column values for B to give us the marginal distribution of A. Hence, we see that the marginal probability of A winning is 0.6. \n\n\n|            | A-lose (0) | A-Win (1)¬† |$Pr(X_{B})$ |\n| :--------- | :--------: | :--------: | :--------: |\n| B-LOSE (0) |    0.3     |        0.1 |        0.4 |\n| B-WIN (1)  |    0.1     |        0.5 |        0.6 |\n| $Pr(X_{A})$|    0.4     |        0.6 |            |\n: The marginal distributions of A and B (shown below and to the right of the joint density values, respectively), achieved by summing the values in each column or row, respectively. {#tbl-horse-race-2}\n\nSo to calculate the probability of a single event we just sum the probabilities of all the potential ways this can happen. This amounts to summing over all potential states of the other variable. \n\n::: {#lem-disc-marg-dist}\n##### Discrete marginal probability distributions\n\n\n{{< video https://youtu.be/M3MlaoW0TT4?si=CvxVNwYQBQzXYnuR >}}\n\n\n\n:::\n\n::: {.callout-tip}\nMarginal distributions gets their name because for discrete random variables, they are obtained by summing a row or column of a table and placing the result in its margins.\n:::\n\nIn the foot size and literacy test example, suppose we want to summarise the distribution for literacy score, irrespective of foot size. We can obtain this distribution by ‚Äòintegrating out‚Äô the dependence on foot size.\n\nAnother way to think about marginal densities is to imagine walking across the landscape of the joint density, where regions of greater density represent hills. To calculate the marginal density for a literacy score of 100 we walk along the horizontal line that corresponds to this score and record the number of calories we burn in walking. If the path is relatively flat, we burn fewer calories and the corresponding marginal density is low. However, if the path includes a large hill, we burn a lot of energy and the marginal density is high.\n\n\n\n::: {#lem-cont-marg-dist}\n\n##### Continuous marginal probability distributions\n\n{{< video https://youtu.be/F97Qf5FGt5M?si=Eam2mN6IKxgLla4k >}}\n\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}